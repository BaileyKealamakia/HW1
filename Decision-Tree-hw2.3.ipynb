{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:13:52.680929500Z",
     "start_time": "2023-09-23T04:13:52.675416200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "  buying  maint  doors persons lug_boot safety  label\n0    low  vhigh      4       4      big    med    acc\n1    low   high  5more       4      med   high  vgood\n2  vhigh    med      2       2      big   high  unacc\n3   high   high      2       2    small   high  unacc\n4  vhigh    low      3       2      big    low  unacc",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>buying</th>\n      <th>maint</th>\n      <th>doors</th>\n      <th>persons</th>\n      <th>lug_boot</th>\n      <th>safety</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>low</td>\n      <td>vhigh</td>\n      <td>4</td>\n      <td>4</td>\n      <td>big</td>\n      <td>med</td>\n      <td>acc</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>low</td>\n      <td>high</td>\n      <td>5more</td>\n      <td>4</td>\n      <td>med</td>\n      <td>high</td>\n      <td>vgood</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>vhigh</td>\n      <td>med</td>\n      <td>2</td>\n      <td>2</td>\n      <td>big</td>\n      <td>high</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>high</td>\n      <td>high</td>\n      <td>2</td>\n      <td>2</td>\n      <td>small</td>\n      <td>high</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>vhigh</td>\n      <td>low</td>\n      <td>3</td>\n      <td>2</td>\n      <td>big</td>\n      <td>low</td>\n      <td>unacc</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"label\"]\n",
    "\n",
    "train_data = pd.read_csv('train.csv',names=col_names)\n",
    "test_data = pd.read_csv('test.csv',names=col_names)\n",
    "\n",
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:13:52.735087100Z",
     "start_time": "2023-09-23T04:13:52.680929500Z"
    }
   },
   "id": "a05a398b14a9594b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# all different info gain helper methods\n",
    "def entropy(target_attribute):\n",
    "    elements, count = np.unique(target_attribute, return_counts=True)\n",
    "    entropy = -np.sum([(count[i]/np.sum(count))*np.log2(count[i]/np.sum(count)) for i in range (len(elements))])\n",
    "    return entropy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:13:52.736040800Z",
     "start_time": "2023-09-23T04:13:52.715963400Z"
    }
   },
   "id": "c7522cc76ad955b9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# now helper for Majority Error\n",
    "def majority_error(target_attribute):\n",
    "    _, count = np.unique(target_attribute, return_counts=True)\n",
    "    majority = np.max(count)\n",
    "    return 1 - majority/np.sum(count)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:13:52.736548Z",
     "start_time": "2023-09-23T04:13:52.720477500Z"
    }
   },
   "id": "48331932e2a949e0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# helper for gini index\n",
    "def gini_index(target_attribute):\n",
    "    elements, count = np.unique(target_attribute, return_counts=True)\n",
    "    giniboi = 1 - np.sum([(count[i]/np.sum(count))**2 for i in range(len(elements))])\n",
    "    return giniboi"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:13:52.737555300Z",
     "start_time": "2023-09-23T04:13:52.726737600Z"
    }
   },
   "id": "2d91b79c09de005d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# now calculating the info gain\n",
    "def infomation_gain(data, split_attribute_name, target_name=\"label\" , citerion=\"entropy\"):\n",
    "    if citerion == \"entropy\":\n",
    "        total_entropy = entropy(data[target_name])\n",
    "    elif citerion == \"majority_error\":\n",
    "        total_entropy = majority_error(data[target_name])\n",
    "    elif citerion == \"gini_index\":\n",
    "        total_entropy = gini_index(data[target_name])\n",
    "    else:\n",
    "        raise ValueError(\"invalid citerion, check spelling or put valid entry\")\n",
    "    \n",
    "    vals, counts = np.unique(data[split_attribute_name], return_counts=True)\n",
    "    weighted_entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
    "    \n",
    "    return total_entropy - weighted_entropy\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:13:52.742556200Z",
     "start_time": "2023-09-23T04:13:52.736040800Z"
    }
   },
   "id": "e953a745f2ebc9f5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# ID3 Algorithm, \n",
    "\n",
    "def ID3(data, og_data, features, target_attribute_name = \"label\", parent_node_class = None, max_depth = None, depth = 0, criterion = \"entropy\"):\n",
    "    # base cases\n",
    "  \n",
    "    #if all the labels in the subseted data are the same return that label (leaf node)\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "    \n",
    "    # now the base case when the data is empty return the max label\n",
    "    elif (len(data) == 0):\n",
    "        return np.unique(og_data[target_attribute_name])[np.argmax(np.unique(og_data[target_attribute_name], return_counts=True)[1])]\n",
    "    \n",
    "    #now there is a third base case for the generalizer. It is the parent_node_class that assigns a label if a leaf node label cannot be decided\n",
    "    #This happens if attributes (features) run out and also when a max depth is reached \n",
    "    elif len(features) == 0 or (max_depth and depth == max_depth):\n",
    "        return parent_node_class\n",
    "\n",
    "    else:\n",
    "        # create root node for tree\n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name], return_counts=True)[1])]\n",
    "    \n",
    "       #find infomation gains for each colomn\n",
    "        info_values = [infomation_gain(data, feature, target_attribute_name, criterion) for feature in features]\n",
    "        #find the highest gain\n",
    "        best_feature_index = np.argmax(info_values)\n",
    "        next_split = features[best_feature_index]\n",
    "        \n",
    "        #take away the feature used to split so that info gain is not calculated on it\n",
    "        features = [i for i in features if i != next_split]\n",
    "\n",
    "        #dictionary for tree to build and return\n",
    "        tree = {next_split:{}}\n",
    "        \n",
    "        #itterate through values in next split and begin the recursion\n",
    "        for val in np.unique(data[next_split]):\n",
    "            subset_data = data.where(data[next_split] == val).dropna()\n",
    "            sub_tree = ID3(subset_data, og_data, features, target_attribute_name, parent_node_class, max_depth, depth+1, criterion)\n",
    "            tree[next_split][val] = sub_tree\n",
    "\n",
    "    return tree\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:13:52.775960200Z",
     "start_time": "2023-09-23T04:13:52.740555800Z"
    }
   },
   "id": "b7834c5b4a1493b4"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:13:52.775960200Z",
     "start_time": "2023-09-23T04:13:52.751490700Z"
    }
   },
   "id": "b835fe46dc5dec11"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "def predict(toPredict, tree, default=1):\n",
    "    # Iterate over each key in the query\n",
    "    for key in toPredict.keys():\n",
    "       \n",
    "        if key in tree.keys():\n",
    "            try:\n",
    "                #use the decision tree to predict value\n",
    "                result = tree[key][toPredict[key]]\n",
    "            except:\n",
    "                \n",
    "                return default\n",
    "\n",
    "            # now go in the tree recuseively to go down sub-branches to find a leaf node\n",
    "            if isinstance(result, dict):\n",
    "                return predict(toPredict, result)\n",
    "        \n",
    "            else:\n",
    "                return result\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:13:52.776961Z",
     "start_time": "2023-09-23T04:13:52.755005700Z"
    }
   },
   "id": "983a8b46f243c239"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#This method sees how accurate the tree is with the data \n",
    "def test(data, tree):\n",
    "    \n",
    "    #makes the dataframe into a dictionary\n",
    "    #use orient = records to use all columns except last one\n",
    "    data_dic = data.iloc[:, :-1].to_dict(orient=\"records\")\n",
    "\n",
    "    #making a df to store predicted values\n",
    "    predicted_vals = pd.DataFrame(columns=[\"predicted\"])\n",
    "\n",
    "    #now fill the predicted df for each value of data\n",
    "    for i in range(len(data)):\n",
    "        predict_value = predict(data_dic[i], tree, 1.0)\n",
    "        predicted_vals.loc[i, \"predicted\"] = predict_value\n",
    "\n",
    "    # now make an accuracy percentage of the percentages that were right\n",
    "    correct_predictions = np.sum(predicted_vals[\"predicted\"] == data[\"label\"])\n",
    "    accuracy_score = (correct_predictions / len(data)) * 100\n",
    "\n",
    "    return accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:13:52.819452Z",
     "start_time": "2023-09-23T04:13:52.768093300Z"
    }
   },
   "id": "197e9bb3e98c432e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# this funtion computes the error for the test and training data and uses the tree constructed in the ID3 algorithm\n",
    "def compute_error(tree, train_data, test_data):\n",
    "   \n",
    "    train_acc = test(train_data, tree)\n",
    "    test_acc = test(test_data, tree)\n",
    "\n",
    "    # since test returns the percentage values that were correct do 100 - right to get the error\n",
    "    train_error = 100 - train_acc\n",
    "    test_error = 100 - test_acc\n",
    "\n",
    "    return train_error, test_error"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:13:52.845453200Z",
     "start_time": "2023-09-23T04:13:52.772629100Z"
    }
   },
   "id": "4330a4958cfa44f1"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion_Car: entropy, Depth_Car: 1, Training Error Car: 30.200000, Test Error Car: 29.670330\n",
      "Criterion_Car: entropy, Depth_Car: 2, Training Error Car: 30.200000, Test Error Car: 29.670330\n",
      "Criterion_Car: entropy, Depth_Car: 3, Training Error Car: 22.200000, Test Error Car: 22.252747\n",
      "Criterion_Car: entropy, Depth_Car: 4, Training Error Car: 13.000000, Test Error Car: 14.835165\n",
      "Criterion_Car: entropy, Depth_Car: 5, Training Error Car: 3.300000, Test Error Car: 11.401099\n",
      "Criterion_Car: entropy, Depth_Car: 6, Training Error Car: 0.000000, Test Error Car: 12.500000\n",
      "Criterion_Car: majority_error, Depth_Car: 1, Training Error Car: 30.200000, Test Error Car: 29.670330\n",
      "Criterion_Car: majority_error, Depth_Car: 2, Training Error Car: 30.200000, Test Error Car: 29.670330\n",
      "Criterion_Car: majority_error, Depth_Car: 3, Training Error Car: 22.200000, Test Error Car: 22.252747\n",
      "Criterion_Car: majority_error, Depth_Car: 4, Training Error Car: 13.000000, Test Error Car: 14.835165\n",
      "Criterion_Car: majority_error, Depth_Car: 5, Training Error Car: 3.300000, Test Error Car: 11.401099\n",
      "Criterion_Car: majority_error, Depth_Car: 6, Training Error Car: 0.000000, Test Error Car: 12.500000\n",
      "Criterion_Car: gini_index, Depth_Car: 1, Training Error Car: 30.200000, Test Error Car: 29.670330\n",
      "Criterion_Car: gini_index, Depth_Car: 2, Training Error Car: 30.200000, Test Error Car: 29.670330\n",
      "Criterion_Car: gini_index, Depth_Car: 3, Training Error Car: 22.200000, Test Error Car: 22.252747\n",
      "Criterion_Car: gini_index, Depth_Car: 4, Training Error Car: 13.000000, Test Error Car: 14.835165\n",
      "Criterion_Car: gini_index, Depth_Car: 5, Training Error Car: 3.300000, Test Error Car: 11.401099\n",
      "Criterion_Car: gini_index, Depth_Car: 6, Training Error Car: 0.000000, Test Error Car: 12.500000\n"
     ]
    }
   ],
   "source": [
    "# Now use all methods to run the experiment to find the test error for each critereion\n",
    "criterions = [\"entropy\", \"majority_error\", \"gini_index\"]\n",
    "max_depths = [1,2,3,4,5,6]\n",
    "results = []\n",
    "\n",
    "\n",
    "for criterion in criterions:\n",
    "    for max_depth in max_depths:\n",
    "        tree = ID3(train_data, train_data, train_data.columns[:-1], max_depth=max_depth, criterion=criterion)\n",
    "        train_error, test_error = compute_error(tree, train_data, test_data)\n",
    "        results.append((criterion, max_depth, train_error, test_error))\n",
    "\n",
    "#results of the TESTS\n",
    "for criterion, depth, train_err, test_err in results:\n",
    "    print(f\"Criterion_Car: {criterion}, Depth_Car: {depth}, Training Error Car: {train_err:.6f}, Test Error Car: {test_err:.6f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:14:09.590064100Z",
     "start_time": "2023-09-23T04:13:52.779960100Z"
    }
   },
   "id": "2068da356b90c5df"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:14:09.600836400Z",
     "start_time": "2023-09-23T04:14:09.590703Z"
    }
   },
   "id": "31aa1cb35582194c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:14:09.601342Z",
     "start_time": "2023-09-23T04:14:09.595017Z"
    }
   },
   "id": "881ef853290d051d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   age          job  marital  education default  balance housing loan  \\\n0   41     services  married  secondary      no        0     yes   no   \n1   48  blue-collar   single  secondary      no      312     yes  yes   \n2   55   technician  married  secondary      no     1938      no  yes   \n3   54       admin.  married   tertiary      no       59     yes   no   \n4   34   management   single   tertiary      no     2646      no   no   \n\n    contact  day_of_week month  duration  campaign  pdays  previous poutcome  \\\n0   unknown            5   may       114         2     -1         0  unknown   \n1  cellular            3   feb       369         2     -1         0  unknown   \n2  cellular           18   aug       193         1    386         3  success   \n3  cellular           10   jul       268         1     -1         0  unknown   \n4  cellular           14   apr       142         1     -1         0  unknown   \n\n     y  \n0   no  \n1   no  \n2  yes  \n3   no  \n4  yes  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day_of_week</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>services</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>0</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>114</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>48</td>\n      <td>blue-collar</td>\n      <td>single</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>312</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>3</td>\n      <td>feb</td>\n      <td>369</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>1938</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>18</td>\n      <td>aug</td>\n      <td>193</td>\n      <td>1</td>\n      <td>386</td>\n      <td>3</td>\n      <td>success</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>54</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>59</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>10</td>\n      <td>jul</td>\n      <td>268</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34</td>\n      <td>management</td>\n      <td>single</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>2646</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>14</td>\n      <td>apr</td>\n      <td>142</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"age\", \"job\", \"marital\", \"education\", \"default\", \"balance\", \"housing\", \"loan\", \"contact\", \"day_of_week\", \"month\", \"duration\", \"campaign\", \"pdays\", \"previous\", \"poutcome\", \"y\"]\n",
    "\n",
    "bank_train = pd.read_csv('bank/train.csv', names=column_names)\n",
    "bank_test = pd.read_csv('bank/test.csv', names=column_names)\n",
    "bank_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:14:09.673079400Z",
     "start_time": "2023-09-23T04:14:09.597538200Z"
    }
   },
   "id": "d7eca3aefa740554"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# convert numberical value to a binary\n",
    "# we find the medium of the column and then that is the threshold \n",
    "# cols have numerical: age, balance, day_of_week, duration, campain, pdays, previous\n",
    "bank_train_data_fixed = bank_train\n",
    "bank_test_data_fixed = bank_test\n",
    "NumCols=['age', 'balance', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous']\n",
    "def changeNumbericToBinary(ListcolName):\n",
    "    bank_train_data_fixed = bank_train.copy()\n",
    "    bank_test_data_fixed = bank_test.copy()\n",
    "\n",
    "    # Find median for each column in the list\n",
    "    for colName in ListcolName:\n",
    "        threshold_train = bank_train_data_fixed[colName].median()\n",
    "        threshold_test = bank_test_data_fixed[colName].median()\n",
    "\n",
    "\n",
    "    # Map the values to 'less' or 'bigger' based on median\n",
    "    bank_train_data_fixed[colName] = bank_train_data_fixed[colName].apply(lambda x: 'less' if x < threshold_train else 'bigger')\n",
    "    bank_test_data_fixed[colName] = bank_test_data_fixed[colName].apply(lambda x: 'less' if x < threshold_test else 'bigger')\n",
    "\n",
    "    return bank_train_data_fixed, bank_test_data_fixed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:14:09.674080500Z",
     "start_time": "2023-09-23T04:14:09.632816200Z"
    }
   },
   "id": "f6931d46effe3c1a"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "   age           job  marital  education default  balance housing loan  \\\n0   41    management   single  secondary      no      764      no   no   \n1   39   blue-collar  married  secondary      no       49     yes   no   \n2   60       retired  married    primary      no        0      no   no   \n3   31  entrepreneur   single   tertiary      no      247     yes  yes   \n4   26       student   single    unknown      no     2020      no   no   \n\n     contact  day_of_week month  duration  campaign  pdays previous poutcome  \\\n0   cellular           12   jun       230         2     -1   bigger  unknown   \n1   cellular           14   may       566         1    370   bigger  failure   \n2  telephone           30   jul       130         3     -1   bigger  unknown   \n3    unknown            2   jun       273         1     -1   bigger  unknown   \n4  telephone           28   jan        42         3     -1   bigger  unknown   \n\n    y  \n0  no  \n1  no  \n2  no  \n3  no  \n4  no  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day_of_week</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>management</td>\n      <td>single</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>764</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>12</td>\n      <td>jun</td>\n      <td>230</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>bigger</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>49</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>14</td>\n      <td>may</td>\n      <td>566</td>\n      <td>1</td>\n      <td>370</td>\n      <td>bigger</td>\n      <td>failure</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>retired</td>\n      <td>married</td>\n      <td>primary</td>\n      <td>no</td>\n      <td>0</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>30</td>\n      <td>jul</td>\n      <td>130</td>\n      <td>3</td>\n      <td>-1</td>\n      <td>bigger</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31</td>\n      <td>entrepreneur</td>\n      <td>single</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>247</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>unknown</td>\n      <td>2</td>\n      <td>jun</td>\n      <td>273</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>bigger</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26</td>\n      <td>student</td>\n      <td>single</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>2020</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>28</td>\n      <td>jan</td>\n      <td>42</td>\n      <td>3</td>\n      <td>-1</td>\n      <td>bigger</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumCols=['age', 'balance', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous']\n",
    "bank_train_data_fixed, bank_test_data_fixed = changeNumbericToBinary(NumCols)\n",
    "\n",
    "bank_test_data_fixed.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:14:09.675078600Z",
     "start_time": "2023-09-23T04:14:09.640445Z"
    }
   },
   "id": "ef26f5b640c9062"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# ID3 Algorithm, fix the target attribute so that it is y\n",
    "\n",
    "def ID3(data, og_data, features, target_attribute_name = \"y\", parent_node_class = None, max_depth = None, depth = 0, criterion = \"entropy\"):\n",
    "    # base cases\n",
    "\n",
    "    #if all the labels in the subseted data are the same return that label (leaf node)\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "\n",
    "    # now the base case when the data is empty return the max label\n",
    "    elif (len(data) == 0):\n",
    "        return np.unique(og_data[target_attribute_name])[np.argmax(np.unique(og_data[target_attribute_name], return_counts=True)[1])]\n",
    "\n",
    "    #now there is a third base case for the generalizer. It is the parent_node_class that assigns a label if a leaf node label cannot be decided\n",
    "    #This happens if attributes (features) run out and also when a max depth is reached \n",
    "    elif len(features) == 0 or (max_depth and depth == max_depth):\n",
    "        return parent_node_class\n",
    "\n",
    "    else:\n",
    "        # create root node for tree\n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name], return_counts=True)[1])]\n",
    "\n",
    "        #find infomation gains for each colomn\n",
    "        info_values = [infomation_gain(data, feature, target_attribute_name, criterion) for feature in features]\n",
    "        #find the highest gain\n",
    "        best_feature_index = np.argmax(info_values)\n",
    "        next_split = features[best_feature_index]\n",
    "\n",
    "        #take away the feature used to split so that info gain is not calculated on it\n",
    "        features = [i for i in features if i != next_split]\n",
    "\n",
    "        #dictionary for tree to build and return\n",
    "        tree = {next_split:{}}\n",
    "\n",
    "        #itterate through values in next split and begin the recursion\n",
    "        for val in np.unique(data[next_split]):\n",
    "            subset_data = data.where(data[next_split] == val).dropna()\n",
    "            sub_tree = ID3(subset_data, og_data, features, target_attribute_name, parent_node_class, max_depth, depth+1, criterion)\n",
    "            tree[next_split][val] = sub_tree\n",
    "\n",
    "    return tree\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:14:09.676078600Z",
     "start_time": "2023-09-23T04:14:09.659254200Z"
    }
   },
   "id": "671ba6a66a5a9e11"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#This method sees how accurate the tree is with the data \n",
    "def test(data, tree):\n",
    "\n",
    "    #makes the dataframe into a dictionary\n",
    "    #use orient = records to use all columns except last one\n",
    "    data_dic = data.iloc[:, :-1].to_dict(orient=\"records\")\n",
    "\n",
    "    #making a df to store predicted values\n",
    "    predicted_vals = pd.DataFrame(columns=[\"predicted\"])\n",
    "\n",
    "    #now fill the predicted df for each value of data\n",
    "    for i in range(len(data)):\n",
    "        predict_value = predict(data_dic[i], tree, 1.0)\n",
    "        predicted_vals.loc[i, \"predicted\"] = predict_value\n",
    "\n",
    "    # now make an accuracy percentage of the percentages that were right\n",
    "    correct_predictions = np.sum(predicted_vals[\"predicted\"] == data[\"y\"])\n",
    "    accuracy_score = (correct_predictions / len(data)) * 100\n",
    "\n",
    "    return accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-23T04:14:09.677078200Z",
     "start_time": "2023-09-23T04:14:09.665275600Z"
    }
   },
   "id": "faa13aef9dddb233"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterions = [\"entropy\", \"majority_error\", \"gini_index\"]\n",
    "banks_max_depth = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "results = []\n",
    "\n",
    "\n",
    "for criterion in criterions:\n",
    "    for max_depth in banks_max_depth:\n",
    "        tree = ID3(bank_train_data_fixed, bank_train_data_fixed, bank_train_data_fixed.columns[:-1], max_depth=max_depth, criterion=criterion)\n",
    "        train_error, test_error = compute_error(tree, bank_train_data_fixed, bank_test_data_fixed)\n",
    "        results.append((criterion, max_depth, train_error, test_error))\n",
    "\n",
    "#results of the TESTS\n",
    "for criterion, depth, train_err, test_err in results:\n",
    "    print(f\"Criterion_bank: {criterion}, Depth_bank: {depth}, Training Error bank: {train_err:.6f}, Test Error bank: {test_err:.6f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-23T04:14:09.673079400Z"
    }
   },
   "id": "dfa8737dd6e71748"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# find columns with unknown as a value\n",
    "columns_with_unknown = bank_train_data_fixed.apply(lambda col: col.apply(lambda x: x == 'unknown')).any()\n",
    "\n",
    "unknowns = columns_with_unknown[columns_with_unknown].index.tolist()\n",
    "print(unknowns)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f71912da4ec90d8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bank_train_data_fixed_noNA = bank_train_data_fixed.copy()\n",
    "bank_test_data_fixed_noNA = bank_test_data_fixed.copy()\n",
    "cols_with_unknown = ['job', 'education', 'contact', 'poutcome']\n",
    "for unknowns in cols_with_unknown:\n",
    "    #     mod_value = bank_test_data_fixed[bank_train_data_fixed[unknowns] != 'unknown'][unknowns].mode()[0]\n",
    "    #     bank_train_data_fixed[unknowns] = bank_train_data_fixed[unknowns].apply(lambda x: mod_value if x = 'unknown')\n",
    "    # Check if the column has 'unknown' values\n",
    "\n",
    "    # Calculate the mode (most frequent value) excluding 'unknown'\n",
    "    mode_val = bank_train_data_fixed_noNA[unknowns][bank_train_data_fixed_noNA[unknowns] != 'unknown'].mode().values[0]\n",
    "    mode_val2 = bank_test_data_fixed_noNA[unknowns][bank_test_data_fixed_noNA[unknowns] != 'unknown'].mode().values[0]\n",
    "    # Replace 'unknown' values with the mode\n",
    "    bank_train_data_fixed_noNA[unknowns] = bank_train_data_fixed_noNA[unknowns].replace('unknown', mode_val)\n",
    "    bank_test_data_fixed_noNA[unknowns] = bank_test_data_fixed_noNA[unknowns].replace('unknown', mode_val2)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "24769038062a5f12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#check to see if unknowns were replaced\n",
    "columns_with_unknown2 = bank_train_data_fixed_noNA.columns[bank_train_data_fixed_noNA.apply(lambda col: col.str.contains('unknown')).any()]\n",
    "print(columns_with_unknown2)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "933b2029c477d216"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterions = [\"entropy\", \"majority_error\", \"gini_index\"]\n",
    "banks_max_depth = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "results = []\n",
    "\n",
    "\n",
    "for criterion in criterions:\n",
    "    for max_depth in banks_max_depth:\n",
    "        tree = ID3(bank_train_data_fixed_noNA, bank_train_data_fixed_noNA, bank_train_data_fixed_noNA.columns[:-1], max_depth=max_depth, criterion=criterion)\n",
    "        train_error, test_error = compute_error(tree, bank_train_data_fixed_noNA, bank_test_data_fixed_noNA)\n",
    "        results.append((criterion, max_depth, train_error, test_error))\n",
    "\n",
    "#results of the TESTS\n",
    "for criterion, depth, train_err, test_err in results:\n",
    "    print(f\"Criterion_bank: {criterion}, Depth_bank: {depth}, Training Error bank: {train_err:.6f}, Test Error bank: {test_err:.6f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b60c71ec8cdfd317"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c63831e8aa2fddc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
